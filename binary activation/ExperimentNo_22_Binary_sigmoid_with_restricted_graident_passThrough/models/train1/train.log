2017-05-22 19:07:19.252999: 6 Layer, Glorut, Without regularization
2017-05-22 19:07:19.253038: Baseline5
2017-05-22 19:07:19.253055: sign activation,pass through gradient
2017-05-22 19:07:19.253069: gradient cancelled if |x| >1 
2017-05-22 19:07:19.253080: Training1...
Testing before starting...
2017-05-22 19:07:19.253098: Learning rates LR: 0.100000 
2017-05-22 19:07:21.647722: TEST valid epoch: -1 Accuracy: 9.7155%, loss: 2.403723038160, i: 39
2017-05-22 19:07:48.663477: Iter: 200 [0], loss: 2.123601, acc: 0.20%, avg_loss: 2.333611, avg_acc: 10.80%
2017-05-22 19:08:09.102644: 
Epoch 0: avg_Loss: 2.241010278634, avg_Acc: 14.683035714286
2017-05-22 19:08:11.534300: TEST valid epoch: 1 Accuracy: 23.3173%, loss: 2.008827582384, i: 39
2017-05-22 19:08:18.494538: Iter: 400 [1], loss: 2.074574, acc: 0.26%, avg_loss: 2.049255, avg_acc: 20.77%
2017-05-22 19:08:45.588716: Iter: 600 [1], loss: 1.882362, acc: 0.29%, avg_loss: 1.985401, avg_acc: 23.73%
2017-05-22 19:08:59.524633: 
Epoch 1: avg_Loss: 1.949946231501, avg_Acc: 25.544642857143
2017-05-22 19:09:01.976516: TEST valid epoch: 2 Accuracy: 32.1514%, loss: 1.794466929558, i: 39
2017-05-22 19:09:15.616506: Iter: 800 [2], loss: 1.728660, acc: 0.41%, avg_loss: 1.789934, avg_acc: 32.42%
2017-05-22 19:09:46.012562: Iter: 1000 [2], loss: 1.545946, acc: 0.44%, avg_loss: 1.745567, avg_acc: 34.52%
2017-05-22 19:09:53.260326: 
Epoch 2: avg_Loss: 1.741508284296, avg_Acc: 35.100446428571
2017-05-22 19:09:55.715754: TEST valid epoch: 3 Accuracy: 37.7404%, loss: 1.678130617509, i: 39
2017-05-22 19:10:16.058141: Iter: 1200 [3], loss: 1.667794, acc: 0.41%, avg_loss: 1.652991, avg_acc: 38.48%
2017-05-22 19:10:43.415173: Iter: 1400 [3], loss: 1.590456, acc: 0.42%, avg_loss: 1.618316, avg_acc: 39.69%
2017-05-22 19:10:43.962304: 
Epoch 3: avg_Loss: 1.622871764047, avg_Acc: 39.781250000000
2017-05-22 19:10:46.418294: TEST valid epoch: 4 Accuracy: 41.2260%, loss: 1.567741177021, i: 39
2017-05-22 19:11:13.493961: Iter: 1600 [4], loss: 1.572994, acc: 0.45%, avg_loss: 1.528053, avg_acc: 43.69%
2017-05-22 19:11:34.698976: 
Epoch 4: avg_Loss: 1.516104444776, avg_Acc: 44.390625000000
2017-05-22 19:11:37.155515: TEST valid epoch: 5 Accuracy: 48.2171%, loss: 1.412251591682, i: 39
2017-05-22 19:11:43.567986: Iter: 1800 [5], loss: 1.593544, acc: 0.41%, avg_loss: 1.447050, avg_acc: 46.20%
2017-05-22 19:12:10.932252: Iter: 2000 [5], loss: 1.324318, acc: 0.51%, avg_loss: 1.429966, avg_acc: 47.44%
2017-05-22 19:12:25.435655: 
Epoch 5: avg_Loss: 1.425210741247, avg_Acc: 47.910714285714
2017-05-22 19:12:27.892027: TEST valid epoch: 6 Accuracy: 51.4423%, loss: 1.365672123738, i: 39
2017-05-22 19:12:40.993164: Iter: 2200 [6], loss: 1.439819, acc: 0.52%, avg_loss: 1.358506, avg_acc: 49.88%
2017-05-22 19:13:08.359816: Iter: 2400 [6], loss: 1.324671, acc: 0.51%, avg_loss: 1.341522, avg_acc: 50.96%
2017-05-22 19:13:16.158345: 
Epoch 6: avg_Loss: 1.338526696818, avg_Acc: 51.404017857143
2017-05-22 19:13:18.615947: TEST valid epoch: 7 Accuracy: 54.6074%, loss: 1.250630837220, i: 39
2017-05-22 19:13:38.435594: Iter: 2600 [7], loss: 1.117504, acc: 0.60%, avg_loss: 1.259291, avg_acc: 54.84%
2017-05-22 19:14:05.804421: Iter: 2800 [7], loss: 1.310707, acc: 0.54%, avg_loss: 1.242776, avg_acc: 55.23%
2017-05-22 19:14:06.898979: 
Epoch 7: avg_Loss: 1.246222651345, avg_Acc: 55.388392857143
2017-05-22 19:14:09.356628: TEST valid epoch: 8 Accuracy: 57.9327%, loss: 1.173668195040, i: 39
2017-05-22 19:14:35.987240: Iter: 3000 [8], loss: 1.176018, acc: 0.54%, avg_loss: 1.193710, avg_acc: 57.07%
2017-05-22 19:14:57.745619: 
Epoch 8: avg_Loss: 1.172378350496, avg_Acc: 58.118303571429
2017-05-22 19:15:00.204013: TEST valid epoch: 9 Accuracy: 63.0609%, loss: 1.042552484916, i: 39
2017-05-22 19:15:06.073119: Iter: 3200 [9], loss: 1.130171, acc: 0.55%, avg_loss: 1.118515, avg_acc: 60.10%
2017-05-22 19:15:33.440445: Iter: 3400 [9], loss: 1.218194, acc: 0.59%, avg_loss: 1.116037, avg_acc: 60.21%
2017-05-22 19:15:48.496880: 
Epoch 9: avg_Loss: 1.109994117873, avg_Acc: 60.796875000000
2017-05-22 19:15:50.954778: TEST valid epoch: 10 Accuracy: 62.3397%, loss: 1.059780237002, i: 39
2017-05-22 19:16:03.538561: Iter: 3600 [10], loss: 1.117001, acc: 0.59%, avg_loss: 1.101078, avg_acc: 60.74%
2017-05-22 19:16:30.907671: Iter: 3800 [10], loss: 1.049216, acc: 0.65%, avg_loss: 1.064521, avg_acc: 62.01%
2017-05-22 19:16:39.255251: 
Epoch 10: avg_Loss: 1.060090719291, avg_Acc: 62.455357142857
2017-05-22 19:16:41.713243: TEST valid epoch: 11 Accuracy: 65.8053%, loss: 0.976776153613, i: 39
2017-05-22 19:17:00.978278: Iter: 4000 [11], loss: 1.090387, acc: 0.57%, avg_loss: 1.014900, avg_acc: 64.05%
2017-05-22 19:17:28.348573: Iter: 4200 [11], loss: 0.946513, acc: 0.62%, avg_loss: 1.004405, avg_acc: 64.45%
2017-05-22 19:17:29.991247: 
Epoch 11: avg_Loss: 1.004773318768, avg_Acc: 64.729910714286
2017-05-22 19:17:32.448469: TEST valid epoch: 12 Accuracy: 67.0272%, loss: 0.921479941943, i: 39
2017-05-22 19:17:58.430350: Iter: 4400 [12], loss: 0.823300, acc: 0.69%, avg_loss: 0.957627, avg_acc: 66.19%
2017-05-22 19:18:20.734827: 
Epoch 12: avg_Loss: 0.966974115372, avg_Acc: 66.111607142857
2017-05-22 19:18:23.192518: TEST valid epoch: 13 Accuracy: 67.4279%, loss: 0.922263853061, i: 39
2017-05-22 19:18:28.500826: Iter: 4600 [13], loss: 0.817526, acc: 0.77%, avg_loss: 0.904762, avg_acc: 67.50%
2017-05-22 19:18:55.871973: Iter: 4800 [13], loss: 0.849959, acc: 0.69%, avg_loss: 0.916323, avg_acc: 67.44%
2017-05-22 19:19:11.470136: 
Epoch 13: avg_Loss: 0.927205598525, avg_Acc: 67.316964285714
2017-05-22 19:19:13.927448: TEST valid epoch: 14 Accuracy: 70.2123%, loss: 0.866675317287, i: 39
2017-05-22 19:19:25.957464: Iter: 5000 [14], loss: 0.992013, acc: 0.66%, avg_loss: 0.898377, avg_acc: 67.99%
2017-05-22 19:19:53.324920: Iter: 5200 [14], loss: 0.900390, acc: 0.66%, avg_loss: 0.902896, avg_acc: 68.18%
2017-05-22 19:20:02.219703: 
Epoch 14: avg_Loss: 0.904000709397, avg_Acc: 68.441964285714
2017-05-22 19:20:04.676640: TEST valid epoch: 15 Accuracy: 68.9303%, loss: 0.895011406678, i: 39
2017-05-22 19:20:23.516334: Iter: 5400 [15], loss: 0.678828, acc: 0.77%, avg_loss: 0.865646, avg_acc: 69.40%
2017-05-22 19:20:50.884898: Iter: 5600 [15], loss: 0.745349, acc: 0.78%, avg_loss: 0.867185, avg_acc: 69.29%
2017-05-22 19:20:53.074608: 
Epoch 15: avg_Loss: 0.870072417259, avg_Acc: 69.453125000000
2017-05-22 19:20:55.531797: TEST valid epoch: 16 Accuracy: 71.4343%, loss: 0.832223713398, i: 39
2017-05-22 19:21:20.983921: Iter: 5800 [16], loss: 0.968077, acc: 0.61%, avg_loss: 0.827805, avg_acc: 70.90%
2017-05-22 19:21:43.834665: 
Epoch 16: avg_Loss: 0.827732502222, avg_Acc: 71.145089285714
2017-05-22 19:21:46.292035: TEST valid epoch: 17 Accuracy: 72.4960%, loss: 0.795003913916, i: 39
2017-05-22 19:21:51.084090: Iter: 6000 [17], loss: 0.888620, acc: 0.70%, avg_loss: 0.795502, avg_acc: 72.66%
2017-05-22 19:22:18.455497: Iter: 6200 [17], loss: 0.667401, acc: 0.79%, avg_loss: 0.795924, avg_acc: 72.03%
2017-05-22 19:22:34.600616: 
Epoch 17: avg_Loss: 0.801365165710, avg_Acc: 72.258928571429
2017-05-22 19:22:37.057113: TEST valid epoch: 18 Accuracy: 72.4760%, loss: 0.797922420196, i: 39
2017-05-22 19:22:48.534412: Iter: 6400 [18], loss: 0.697226, acc: 0.73%, avg_loss: 0.765201, avg_acc: 72.78%
2017-05-22 19:23:15.902725: Iter: 6600 [18], loss: 0.799515, acc: 0.73%, avg_loss: 0.784047, avg_acc: 72.37%
2017-05-22 19:23:25.343489: 
Epoch 18: avg_Loss: 0.785116282531, avg_Acc: 72.549107142857
2017-05-22 19:23:27.799873: TEST valid epoch: 19 Accuracy: 73.0769%, loss: 0.767959695596, i: 39
2017-05-22 19:23:45.977377: Iter: 6800 [19], loss: 1.012912, acc: 0.68%, avg_loss: 0.753855, avg_acc: 73.44%
2017-05-22 19:24:13.350246: Iter: 7000 [19], loss: 0.683257, acc: 0.77%, avg_loss: 0.758160, avg_acc: 73.27%
2017-05-22 19:24:16.087133: 
Epoch 19: avg_Loss: 0.759527693050, avg_Acc: 73.450892857143
2017-05-22 19:24:18.544325: TEST valid epoch: 20 Accuracy: 72.7564%, loss: 0.816466138913, i: 39
2017-05-22 19:24:18.544368: LR CHANGE: 0.010000000000
2017-05-22 19:24:43.401422: Iter: 7200 [20], loss: 0.555170, acc: 0.79%, avg_loss: 0.678349, avg_acc: 76.05%
2017-05-22 19:25:06.799707: 
Epoch 20: avg_Loss: 0.662149821350, avg_Acc: 77.205357142857
2017-05-22 19:25:09.256784: TEST valid epoch: 21 Accuracy: 76.9431%, loss: 0.674160919892, i: 39
2017-05-22 19:25:13.446305: Iter: 7400 [21], loss: 0.704343, acc: 0.73%, avg_loss: 0.656492, avg_acc: 76.56%
2017-05-22 19:25:40.808982: Iter: 7600 [21], loss: 0.608553, acc: 0.82%, avg_loss: 0.630817, avg_acc: 77.79%
2017-05-22 19:25:57.502899: 
Epoch 21: avg_Loss: 0.629744847843, avg_Acc: 78.160714285714
2017-05-22 19:25:59.959838: TEST valid epoch: 22 Accuracy: 76.5625%, loss: 0.670132234310, i: 39
2017-05-22 19:26:10.960889: Iter: 7800 [22], loss: 0.691938, acc: 0.80%, avg_loss: 0.622378, avg_acc: 78.29%
2017-05-22 19:26:38.324704: Iter: 8000 [22], loss: 0.500911, acc: 0.82%, avg_loss: 0.619753, avg_acc: 78.38%
2017-05-22 19:26:48.313393: 
Epoch 22: avg_Loss: 0.621929831931, avg_Acc: 78.600446428571
2017-05-22 19:26:50.769726: TEST valid epoch: 23 Accuracy: 76.6426%, loss: 0.664663540247, i: 39
2017-05-22 19:27:08.378713: Iter: 8200 [23], loss: 0.571878, acc: 0.78%, avg_loss: 0.606384, avg_acc: 78.88%
2017-05-22 19:27:35.747639: Iter: 8400 [23], loss: 0.499567, acc: 0.85%, avg_loss: 0.608966, avg_acc: 78.74%
2017-05-22 19:27:39.030853: 
Epoch 23: avg_Loss: 0.610437223315, avg_Acc: 78.933035714286
2017-05-22 19:27:41.487590: TEST valid epoch: 24 Accuracy: 77.6242%, loss: 0.657468602443, i: 39
2017-05-22 19:28:05.797485: Iter: 8600 [24], loss: 0.746482, acc: 0.75%, avg_loss: 0.607196, avg_acc: 78.77%
2017-05-22 19:28:29.743117: 
Epoch 24: avg_Loss: 0.606477672117, avg_Acc: 79.055803571429
2017-05-22 19:28:32.199836: TEST valid epoch: 25 Accuracy: 76.8229%, loss: 0.657250380669, i: 39
2017-05-22 19:28:35.846531: Iter: 8800 [25], loss: 0.718473, acc: 0.74%, avg_loss: 0.629702, avg_acc: 77.91%
2017-05-22 19:29:03.210040: Iter: 9000 [25], loss: 0.486373, acc: 0.83%, avg_loss: 0.607296, avg_acc: 78.72%
2017-05-22 19:29:20.452653: 
Epoch 25: avg_Loss: 0.604314665028, avg_Acc: 79.120535714286
2017-05-22 19:29:22.909615: TEST valid epoch: 26 Accuracy: 77.7244%, loss: 0.656170905401, i: 39
2017-05-22 19:29:33.265592: Iter: 9200 [26], loss: 0.629344, acc: 0.74%, avg_loss: 0.590785, avg_acc: 79.95%
2017-05-22 19:30:00.628466: Iter: 9400 [26], loss: 0.636863, acc: 0.77%, avg_loss: 0.592130, avg_acc: 79.39%
2017-05-22 19:30:11.163318: 
Epoch 26: avg_Loss: 0.598848276649, avg_Acc: 79.439732142857
2017-05-22 19:30:13.619501: TEST valid epoch: 27 Accuracy: 77.6442%, loss: 0.650603303543, i: 39
2017-05-22 19:30:30.670794: Iter: 9600 [27], loss: 0.616052, acc: 0.81%, avg_loss: 0.597434, avg_acc: 79.09%
2017-05-22 19:30:58.035964: Iter: 9800 [27], loss: 0.760782, acc: 0.74%, avg_loss: 0.592409, avg_acc: 79.14%
2017-05-22 19:31:01.867650: 
Epoch 27: avg_Loss: 0.593287018367, avg_Acc: 79.392857142857
2017-05-22 19:31:04.323638: TEST valid epoch: 28 Accuracy: 77.2837%, loss: 0.650871621493, i: 39
2017-05-22 19:31:28.084672: Iter: 10000 [28], loss: 0.619082, acc: 0.80%, avg_loss: 0.589533, avg_acc: 79.66%
2017-05-22 19:31:52.572759: 
Epoch 28: avg_Loss: 0.587436612674, avg_Acc: 79.758928571429
2017-05-22 19:31:55.028650: TEST valid epoch: 29 Accuracy: 77.9247%, loss: 0.641541823363, i: 39
2017-05-22 19:31:58.138562: Iter: 10200 [29], loss: 0.578312, acc: 0.80%, avg_loss: 0.583519, avg_acc: 80.25%
2017-05-22 19:32:25.504289: Iter: 10400 [29], loss: 0.501048, acc: 0.84%, avg_loss: 0.582419, avg_acc: 79.56%
2017-05-22 19:32:43.291621: 
Epoch 29: avg_Loss: 0.581861592872, avg_Acc: 79.881696428571
2017-05-22 19:32:45.747976: TEST valid epoch: 30 Accuracy: 77.6442%, loss: 0.643296618492, i: 39
2017-05-22 19:32:55.659654: Iter: 10600 [30], loss: 0.459918, acc: 0.84%, avg_loss: 0.576766, avg_acc: 79.79%
2017-05-22 19:33:23.023130: Iter: 10800 [30], loss: 0.558468, acc: 0.80%, avg_loss: 0.578159, avg_acc: 79.83%
2017-05-22 19:33:34.108567: 
Epoch 30: avg_Loss: 0.579792160307, avg_Acc: 79.910714285714
2017-05-22 19:33:36.564765: TEST valid epoch: 31 Accuracy: 77.7043%, loss: 0.646211910706, i: 39
2017-05-22 19:33:53.072365: Iter: 11000 [31], loss: 0.602677, acc: 0.80%, avg_loss: 0.580830, avg_acc: 79.67%
2017-05-22 19:34:20.441089: Iter: 11200 [31], loss: 0.608772, acc: 0.76%, avg_loss: 0.576037, avg_acc: 79.99%
2017-05-22 19:34:24.819452: 
Epoch 31: avg_Loss: 0.577263939466, avg_Acc: 80.189732142857
2017-05-22 19:34:27.275839: TEST valid epoch: 32 Accuracy: 77.6442%, loss: 0.646629897448, i: 39
2017-05-22 19:34:50.500967: Iter: 11400 [32], loss: 0.542893, acc: 0.79%, avg_loss: 0.573974, avg_acc: 80.14%
2017-05-22 19:35:15.544811: 
Epoch 32: avg_Loss: 0.575954309872, avg_Acc: 80.290178571429
2017-05-22 19:35:18.001906: TEST valid epoch: 33 Accuracy: 77.1034%, loss: 0.659779620476, i: 39
2017-05-22 19:35:20.570055: Iter: 11600 [33], loss: 0.606421, acc: 0.78%, avg_loss: 0.554845, avg_acc: 80.33%
2017-05-22 19:35:47.940206: Iter: 11800 [33], loss: 0.583803, acc: 0.80%, avg_loss: 0.568496, avg_acc: 80.06%
2017-05-22 19:36:06.278115: 
Epoch 33: avg_Loss: 0.569706393395, avg_Acc: 80.303571428571
2017-05-22 19:36:08.734963: TEST valid epoch: 34 Accuracy: 78.5657%, loss: 0.635551709395, i: 39
2017-05-22 19:36:18.006585: Iter: 12000 [34], loss: 0.546211, acc: 0.82%, avg_loss: 0.567360, avg_acc: 80.30%
2017-05-22 19:36:45.373689: Iter: 12200 [34], loss: 0.532628, acc: 0.82%, avg_loss: 0.564049, avg_acc: 80.21%
2017-05-22 19:36:57.005031: 
Epoch 34: avg_Loss: 0.565972763726, avg_Acc: 80.428571428571
2017-05-22 19:36:59.462050: TEST valid epoch: 35 Accuracy: 77.6442%, loss: 0.645342502839, i: 39
2017-05-22 19:37:15.439490: Iter: 12400 [35], loss: 0.501045, acc: 0.83%, avg_loss: 0.559845, avg_acc: 80.41%
2017-05-22 19:37:42.805633: Iter: 12600 [35], loss: 0.672569, acc: 0.79%, avg_loss: 0.562932, avg_acc: 80.28%
2017-05-22 19:37:47.732203: 
Epoch 35: avg_Loss: 0.565648569124, avg_Acc: 80.468750000000
2017-05-22 19:37:50.189289: TEST valid epoch: 36 Accuracy: 77.7043%, loss: 0.646480022333, i: 39
2017-05-22 19:38:12.869811: Iter: 12800 [36], loss: 0.490751, acc: 0.87%, avg_loss: 0.554115, avg_acc: 80.82%
2017-05-22 19:38:38.461434: 
Epoch 36: avg_Loss: 0.556008800353, avg_Acc: 80.841517857143
2017-05-22 19:38:40.918539: TEST valid epoch: 37 Accuracy: 78.1050%, loss: 0.640779942274, i: 39
2017-05-22 19:38:43.039746: Iter: 13000 [37], loss: 0.538016, acc: 0.80%, avg_loss: 0.550458, avg_acc: 80.59%
2017-05-22 19:39:10.411343: Iter: 13200 [37], loss: 0.633077, acc: 0.75%, avg_loss: 0.555414, avg_acc: 80.58%
2017-05-22 19:39:29.299558: 
Epoch 37: avg_Loss: 0.556913906251, avg_Acc: 80.779017857143
2017-05-22 19:39:31.755669: TEST valid epoch: 38 Accuracy: 77.9447%, loss: 0.647643368978, i: 39
2017-05-22 19:39:40.488723: Iter: 13400 [38], loss: 0.495173, acc: 0.84%, avg_loss: 0.543491, avg_acc: 81.20%
2017-05-22 19:40:07.857386: Iter: 13600 [38], loss: 0.502829, acc: 0.82%, avg_loss: 0.545509, avg_acc: 80.92%
2017-05-22 19:40:20.035554: 
Epoch 38: avg_Loss: 0.551223192215, avg_Acc: 80.950892857143
2017-05-22 19:40:22.492130: TEST valid epoch: 39 Accuracy: 77.8646%, loss: 0.637120278218, i: 39
2017-05-22 19:40:37.928251: Iter: 13800 [39], loss: 0.538579, acc: 0.80%, avg_loss: 0.549231, avg_acc: 80.81%
2017-05-22 19:41:05.300294: Iter: 14000 [39], loss: 0.577500, acc: 0.77%, avg_loss: 0.546987, avg_acc: 80.87%
2017-05-22 19:41:10.775916: 
Epoch 39: avg_Loss: 0.546706401621, avg_Acc: 81.227678571429
2017-05-22 19:41:13.339746: TEST valid epoch: 40 Accuracy: 78.6659%, loss: 0.635870464337, i: 39
2017-05-22 19:41:13.339810: LR CHANGE: 0.001000000000
2017-05-22 19:41:45.430103: Iter: 14200 [40], loss: 0.526646, acc: 0.82%, avg_loss: 0.531537, avg_acc: 81.62%
2017-05-22 19:42:26.458896: 
Epoch 40: avg_Loss: 0.531460659759, avg_Acc: 81.738839285714
2017-05-22 19:42:30.167604: TEST valid epoch: 41 Accuracy: 78.5056%, loss: 0.622474273046, i: 39
2017-05-22 19:42:32.291446: Iter: 14400 [41], loss: 0.370236, acc: 0.88%, avg_loss: 0.532259, avg_acc: 80.90%
2017-05-22 19:43:15.785897: Iter: 14600 [41], loss: 0.591313, acc: 0.78%, avg_loss: 0.525940, avg_acc: 81.50%
2017-05-22 19:43:46.448616: 
Epoch 41: avg_Loss: 0.527293955939, avg_Acc: 81.783482142857
2017-05-22 19:43:50.353657: TEST valid epoch: 42 Accuracy: 78.3053%, loss: 0.621782394556, i: 39
2017-05-22 19:44:02.977111: Iter: 14800 [42], loss: 0.542730, acc: 0.78%, avg_loss: 0.520119, avg_acc: 81.76%
2017-05-22 19:44:46.114200: Iter: 15000 [42], loss: 0.370941, acc: 0.88%, avg_loss: 0.525484, avg_acc: 81.50%
2017-05-22 19:45:06.605349: 
Epoch 42: avg_Loss: 0.526977847474, avg_Acc: 81.796875000000
2017-05-22 19:45:10.509463: TEST valid epoch: 43 Accuracy: 78.6859%, loss: 0.623176915523, i: 39
2017-05-22 19:45:33.759739: Iter: 15200 [43], loss: 0.507228, acc: 0.81%, avg_loss: 0.523325, avg_acc: 81.90%
2017-05-22 19:46:17.349249: Iter: 15400 [43], loss: 0.405851, acc: 0.83%, avg_loss: 0.522982, avg_acc: 81.86%
2017-05-22 19:46:26.704414: 
Epoch 43: avg_Loss: 0.527365705626, avg_Acc: 81.997767857143
2017-05-22 19:46:30.606480: TEST valid epoch: 44 Accuracy: 78.6258%, loss: 0.623247884787, i: 39
2017-05-22 19:47:04.391246: Iter: 15600 [44], loss: 0.561195, acc: 0.80%, avg_loss: 0.526745, avg_acc: 81.67%
2017-05-22 19:47:46.624171: 
Epoch 44: avg_Loss: 0.527241729072, avg_Acc: 81.886160714286
2017-05-22 19:47:50.524520: TEST valid epoch: 45 Accuracy: 78.5457%, loss: 0.623106805178, i: 39
2017-05-22 19:47:51.897502: Iter: 15800 [45], loss: 0.407030, acc: 0.88%, avg_loss: 0.500135, avg_acc: 83.44%
2017-05-22 19:48:35.101736: Iter: 16000 [45], loss: 0.578559, acc: 0.79%, avg_loss: 0.529403, avg_acc: 81.79%
2017-05-22 19:49:06.387573: 
Epoch 45: avg_Loss: 0.527133324913, avg_Acc: 81.991071428571
2017-05-22 19:49:10.226833: TEST valid epoch: 46 Accuracy: 78.5256%, loss: 0.631553896727, i: 39
2017-05-22 19:49:22.151399: Iter: 16200 [46], loss: 0.410752, acc: 0.82%, avg_loss: 0.516386, avg_acc: 81.80%
2017-05-22 19:50:05.114060: Iter: 16400 [46], loss: 0.464035, acc: 0.84%, avg_loss: 0.515887, avg_acc: 81.81%
2017-05-22 19:50:26.152276: 
Epoch 46: avg_Loss: 0.522250605055, avg_Acc: 81.870535714286
2017-05-22 19:50:30.054681: TEST valid epoch: 47 Accuracy: 78.1050%, loss: 0.626385227228, i: 39
2017-05-22 19:50:52.426318: Iter: 16600 [47], loss: 0.644803, acc: 0.80%, avg_loss: 0.530558, avg_acc: 81.57%
2017-05-22 19:51:35.364571: Iter: 16800 [47], loss: 0.574382, acc: 0.81%, avg_loss: 0.525833, avg_acc: 81.68%
2017-05-22 19:51:45.723923: 
Epoch 47: avg_Loss: 0.524977010744, avg_Acc: 81.982142857143
2017-05-22 19:51:49.766263: TEST valid epoch: 48 Accuracy: 78.6859%, loss: 0.629605678412, i: 39
2017-05-22 19:52:22.860740: Iter: 17000 [48], loss: 0.537472, acc: 0.83%, avg_loss: 0.528225, avg_acc: 81.65%
2017-05-22 19:53:05.658456: 
Epoch 48: avg_Loss: 0.526641076037, avg_Acc: 81.993303571429
2017-05-22 19:53:09.286738: TEST valid epoch: 49 Accuracy: 78.3454%, loss: 0.632780728432, i: 39
2017-05-22 19:53:09.797085: Iter: 17200 [49], loss: 0.339642, acc: 0.88%, avg_loss: 0.339642, avg_acc: 87.50%
2017-05-22 19:53:52.997014: Iter: 17400 [49], loss: 0.644256, acc: 0.80%, avg_loss: 0.519547, avg_acc: 81.74%
2017-05-22 19:54:25.326246: 
Epoch 49: avg_Loss: 0.526179971780, avg_Acc: 81.908482142857
2017-05-22 19:54:29.195848: TEST valid epoch: 50 Accuracy: 78.3854%, loss: 0.627171650911, i: 39
2017-05-22 19:54:40.015928: Iter: 17600 [50], loss: 0.602326, acc: 0.78%, avg_loss: 0.528571, avg_acc: 81.09%
2017-05-22 19:55:23.249854: Iter: 17800 [50], loss: 0.522337, acc: 0.79%, avg_loss: 0.523439, avg_acc: 81.64%
2017-05-22 19:55:45.084795: 
Epoch 50: avg_Loss: 0.523577977078, avg_Acc: 81.950892857143
2017-05-22 19:55:48.704832: TEST valid epoch: 51 Accuracy: 78.5457%, loss: 0.626990736295, i: 39
2017-05-22 19:56:10.116218: Iter: 18000 [51], loss: 0.454254, acc: 0.83%, avg_loss: 0.531047, avg_acc: 81.37%
2017-05-22 19:56:52.948659: Iter: 18200 [51], loss: 0.500726, acc: 0.82%, avg_loss: 0.525337, avg_acc: 81.59%
2017-05-22 19:57:04.375789: 
Epoch 51: avg_Loss: 0.525199524675, avg_Acc: 81.892857142857
2017-05-22 19:57:08.277404: TEST valid epoch: 52 Accuracy: 78.5056%, loss: 0.625291173275, i: 39
2017-05-22 19:57:40.354500: Iter: 18400 [52], loss: 0.521005, acc: 0.80%, avg_loss: 0.528843, avg_acc: 81.05%
2017-05-22 19:58:23.274159: Iter: 18600 [52], loss: 0.479229, acc: 0.80%, avg_loss: 0.524499, avg_acc: 81.38%
2017-05-22 19:58:23.964175: 
Epoch 52: avg_Loss: 0.526473859804, avg_Acc: 81.582589285714
2017-05-22 19:58:27.865711: TEST valid epoch: 53 Accuracy: 78.1450%, loss: 0.625949903176, i: 39
2017-05-22 19:59:10.255915: Iter: 18800 [53], loss: 0.739011, acc: 0.77%, avg_loss: 0.522454, avg_acc: 81.95%
2017-05-22 19:59:43.366797: 
Epoch 53: avg_Loss: 0.522286090255, avg_Acc: 82.256696428571
2017-05-22 19:59:47.222023: TEST valid epoch: 54 Accuracy: 78.4856%, loss: 0.626674757554, i: 39
2017-05-22 19:59:57.321694: Iter: 19000 [54], loss: 0.440962, acc: 0.83%, avg_loss: 0.534238, avg_acc: 81.35%
2017-05-22 20:00:33.626244: Iter: 19200 [54], loss: 0.543654, acc: 0.80%, avg_loss: 0.524612, avg_acc: 81.69%
2017-05-22 20:00:48.140915: 
Epoch 54: avg_Loss: 0.522953546047, avg_Acc: 81.890625000000
2017-05-22 20:00:50.606333: TEST valid epoch: 55 Accuracy: 78.2853%, loss: 0.626447674556, i: 39
2017-05-22 20:01:03.854581: Iter: 19400 [55], loss: 0.617087, acc: 0.77%, avg_loss: 0.519439, avg_acc: 82.20%
2017-05-22 20:01:31.262537: Iter: 19600 [55], loss: 0.506455, acc: 0.83%, avg_loss: 0.520722, avg_acc: 81.81%
2017-05-22 20:01:38.936062: 
Epoch 55: avg_Loss: 0.525715156198, avg_Acc: 81.921875000000
2017-05-22 20:01:41.396086: TEST valid epoch: 56 Accuracy: 78.1450%, loss: 0.626438705585, i: 39
2017-05-22 20:02:01.357324: Iter: 19800 [56], loss: 0.549785, acc: 0.80%, avg_loss: 0.514452, avg_acc: 82.05%
2017-05-22 20:02:28.758844: Iter: 20000 [56], loss: 0.505391, acc: 0.86%, avg_loss: 0.521514, avg_acc: 81.81%
2017-05-22 20:02:29.718301: 
Epoch 56: avg_Loss: 0.522738532169, avg_Acc: 82.017857142857
2017-05-22 20:02:32.177824: TEST valid epoch: 57 Accuracy: 78.2252%, loss: 0.626013113902, i: 39
2017-05-22 20:02:58.851888: Iter: 20200 [57], loss: 0.511825, acc: 0.83%, avg_loss: 0.519211, avg_acc: 81.85%
2017-05-22 20:03:20.498447: 
Epoch 57: avg_Loss: 0.519271113276, avg_Acc: 82.120535714286
2017-05-22 20:03:22.957090: TEST valid epoch: 58 Accuracy: 78.2252%, loss: 0.629479492322, i: 39
2017-05-22 20:03:28.948872: Iter: 20400 [58], loss: 0.468203, acc: 0.83%, avg_loss: 0.533052, avg_acc: 81.81%
2017-05-22 20:03:56.350318: Iter: 20600 [58], loss: 0.475233, acc: 0.81%, avg_loss: 0.519507, avg_acc: 81.76%
2017-05-22 20:04:11.285094: 
Epoch 58: avg_Loss: 0.521096016083, avg_Acc: 81.935267857143
2017-05-22 20:04:13.744519: TEST valid epoch: 59 Accuracy: 78.4054%, loss: 0.627034590030, i: 39
2017-05-22 20:04:26.535558: Iter: 20800 [59], loss: 0.663068, acc: 0.74%, avg_loss: 0.517795, avg_acc: 81.95%
2017-05-22 20:04:53.941481: Iter: 21000 [59], loss: 0.555197, acc: 0.84%, avg_loss: 0.517732, avg_acc: 81.92%
2017-05-22 20:05:02.163177: 
Epoch 59: avg_Loss: 0.520838604399, avg_Acc: 82.055803571429
2017-05-22 20:05:04.623657: TEST valid epoch: 60 Accuracy: 78.8061%, loss: 0.622445527560, i: 39
2017-05-22 20:05:04.623700: LR CHANGE: 0.000100000000
2017-05-22 20:05:04.871962: 
Testing at last epoch...
2017-05-22 20:05:09.750143: epoch: 60 Accuracy: 77.0733%, loss: 0.666584187975, i: 78
2017-05-22 20:05:09.750195: Exiting train...
